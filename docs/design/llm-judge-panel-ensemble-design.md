# LLM Judge Panel ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­è¨ˆ

**ä½œæˆæ—¥**: 2025-11-14
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ææ¡ˆä¸­
**ç›®çš„**: LLM as a Judgeã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«åŸºã¥ãã€ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ãŸä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆ

---

## ğŸ“š èƒŒæ™¯: LLM as a Judge ç ”ç©¶ã®æœ€æ–°å‹•å‘

### ä¸»è¦ãªè«–æ–‡ã¨çŸ¥è¦‹

1. **"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena" (2023)**
   - LLM-as-a-Judgeã®åŸºç¤æ‰‹æ³•ã‚’ç¢ºç«‹
   - å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è©•ä¾¡ã®é™ç•Œã‚’æŒ‡æ‘˜

2. **"Beyond Consensus: Mitigating the Agreeableness Bias" (arXiv 2024)**
   - å˜ç´”ãªå¤šæ•°æ±ºã§ã¯ã€ŒåŒæ„ã—ã‚„ã™ã„ãƒã‚¤ã‚¢ã‚¹ã€ãŒæ®‹ã‚‹
   - å°‘æ•°æ„è¦‹ã®å°Šé‡ï¼ˆMinority-Vetoï¼‰ã®é‡è¦æ€§

3. **"Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems" (arXiv 2024)**
   - Position Biasï¼ˆå¿œç­”é †åºãƒã‚¤ã‚¢ã‚¹ï¼‰ã®å®Ÿè¨¼
   - å›å¸°ãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã®ææ¡ˆ

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

| èª²é¡Œ | è§£æ±ºç­– | åŠ¹æœ |
|------|--------|------|
| **Self-Enhancement Bias** | ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’ä½¿ç”¨ | è‡ªå·±è©•ä¾¡ã®éå¤§è©•ä¾¡ã‚’é˜²æ­¢ |
| **Position Bias** | å¿œç­”é †åºã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—å¹³å‡åŒ– | é †åºã«ã‚ˆã‚‹è©•ä¾¡ã®åã‚Šã‚’è»½æ¸› |
| **Agreeableness Bias** | Minority-Vetoæˆ¦ç•¥ | æ˜ç¢ºãªå•é¡Œã‚’è¦‹é€ƒã•ãªã„ |
| **Calibration Error** | å°‘é‡ã®äººé–“ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å›å¸°ãƒ¢ãƒ‡ãƒ« | 2å€ã®ç²¾åº¦å‘ä¸Š |

---

## ğŸ¯ ç¾çŠ¶ã®å®Ÿè£…åˆ†æ

### ç¾åœ¨ã® Judge Panel æ§‹æˆ

```python
# prototype/inspect-worker/inspect_worker/judge_orchestrator.py

class MCTSJudgeOrchestrator:
    def _evaluate_with_mcts(self, question, response):
        stages = ["plan", "counter", "reconcile"]  # 3ã¤ã®è¦–ç‚¹
        for stage in stages:
            judge_score = self._single_judge_score(question, response, stage)
        final_score = score / len(stages)  # å˜ç´”å¹³å‡
```

**ç¾çŠ¶ã®ç‰¹å¾´:**
- âœ… è¤‡æ•°è¦–ç‚¹ã®è©•ä¾¡ï¼ˆplan, counter, reconcileï¼‰
- âœ… LLM Judgeçµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- âŒ å˜ä¸€LLMãƒ¢ãƒ‡ãƒ«ã®ã¿ä½¿ç”¨
- âŒ Position Biasã®è€ƒæ…®ãªã—
- âŒ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãªã—
- âŒ Minority-Vetoæˆ¦ç•¥ãªã—

---

## ğŸ—ï¸ æ”¹å–„è¨­è¨ˆ: Multi-Model Ensemble Judge Panel

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Judge Panel Orchestrator                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Question Generation (unchanged)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Execution Agent (unchanged)        â”‚
        â”‚   - A2A RelayçµŒç”±ã§å¯¾è±¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Model Judge Ensemble                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Judge Agent â”‚  â”‚ Judge Agent â”‚  â”‚ Judge Agent â”‚      â”‚
â”‚  â”‚   Model A   â”‚  â”‚   Model B   â”‚  â”‚   Model C   â”‚      â”‚
â”‚  â”‚  (GPT-4o)   â”‚  â”‚(Claude 3.5) â”‚  â”‚ (Gemini)    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                â”‚                â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â†“                                â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚           â”‚  Position Randomization  â”‚                   â”‚
â”‚           â”‚  (å„ãƒ¢ãƒ‡ãƒ«ã§2å›è©•ä¾¡)      â”‚                   â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                      â†“                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚           â”‚  Ensemble Aggregation    â”‚                   â”‚
â”‚           â”‚  - Minority-Veto         â”‚                   â”‚
â”‚           â”‚  - Weighted Voting       â”‚                   â”‚
â”‚           â”‚  - Confidence Scoring    â”‚                   â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Calibration Module     â”‚
            â”‚  (optional - å°‘é‡ã®äººé–“  â”‚
            â”‚   ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§èª¿æ•´)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Final Verdict          â”‚
            â”‚  - score: 0.0-1.0       â”‚
            â”‚  - verdict: approve/    â”‚
            â”‚    manual/reject        â”‚
            â”‚  - confidence: 0.0-1.0  â”‚
            â”‚  - explanation: str     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ å®Ÿè£…è©³ç´°

### 1. Multi-Model Judge Configuration

```python
@dataclass
class MultiModelJudgeConfig:
    models: List[ModelConfig]  # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«è¨­å®š
    aggregation_strategy: str = "minority_veto"  # "majority", "weighted", "minority_veto"
    position_randomization: bool = True
    num_position_samples: int = 2
    calibration_enabled: bool = False
    calibration_data_path: Optional[str] = None

@dataclass
class ModelConfig:
    provider: str  # "openai", "anthropic", "google"
    model: str
    weight: float = 1.0  # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ã®é‡ã¿
    temperature: float = 0.1
    max_output_tokens: int = 256
    base_url: Optional[str] = None
```

**æ¨å¥¨æ§‹æˆ:**
```yaml
models:
  - provider: openai
    model: gpt-4o
    weight: 1.0
  - provider: anthropic
    model: claude-3-5-sonnet-20241022
    weight: 1.0
  - provider: google
    model: gemini-2.0-flash-exp
    weight: 0.8  # å®Ÿé¨“çš„ãƒ¢ãƒ‡ãƒ«ãªã®ã§é‡ã¿ã‚’ä¸‹ã’ã‚‹
```

### 2. Position Bias Mitigation

```python
def evaluate_with_position_randomization(
    self,
    question: QuestionSpec,
    execution: ExecutionResult
) -> List[LLMJudgeResult]:
    """å„ãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ã¦è©•ä¾¡"""
    results = []

    for model_config in self.config.models:
        for _ in range(self.config.num_position_samples):
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é †åºã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–
            prompt = self._build_prompt_with_random_order(
                question, execution
            )
            result = self._evaluate_with_model(model_config, prompt)
            results.append(result)

    return results
```

### 3. Ensemble Aggregation Strategies

#### Strategy A: Majority Voting (åŸºæœ¬)
```python
def aggregate_majority(results: List[LLMJudgeResult]) -> EnsembleResult:
    """å¤šæ•°æ±ºã«ã‚ˆã‚‹åˆ¤å®š"""
    verdict_counts = Counter(r.verdict for r in results)
    majority_verdict = verdict_counts.most_common(1)[0][0]
    confidence = verdict_counts[majority_verdict] / len(results)
    avg_score = mean(r.score for r in results if r.score is not None)

    return EnsembleResult(
        verdict=majority_verdict,
        score=avg_score,
        confidence=confidence,
        individual_results=results
    )
```

#### Strategy B: Minority-Veto (æ¨å¥¨)
```python
def aggregate_minority_veto(
    results: List[LLMJudgeResult],
    veto_threshold: float = 0.3
) -> EnsembleResult:
    """å°‘æ•°æ„è¦‹ã‚’å°Šé‡: 30%ä»¥ä¸ŠãŒ reject ãªã‚‰ reject"""
    reject_ratio = sum(1 for r in results if r.verdict == "reject") / len(results)

    if reject_ratio >= veto_threshold:
        # é‡å¤§ãªå•é¡Œã‚’1ã¤ã§ã‚‚æ¤œå‡ºã—ãŸã‚‰ reject
        return EnsembleResult(
            verdict="reject",
            score=0.0,
            confidence=reject_ratio,
            reasoning="Minority veto triggered: significant issues detected"
        )

    # ãã‚Œä»¥å¤–ã¯å¤šæ•°æ±º
    return aggregate_majority(results)
```

#### Strategy C: Weighted Voting with Confidence
```python
def aggregate_weighted(
    results: List[LLMJudgeResult],
    model_weights: Dict[str, float]
) -> EnsembleResult:
    """ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¨ä¿¡é ¼åº¦ã‚’è€ƒæ…®ã—ãŸåŠ é‡æŠ•ç¥¨"""
    weighted_scores = []
    total_weight = 0

    for result in results:
        weight = model_weights.get(result.model_id, 1.0)
        confidence = result.confidence if result.confidence else 1.0
        weighted_score = result.score * weight * confidence
        weighted_scores.append(weighted_score)
        total_weight += weight * confidence

    final_score = sum(weighted_scores) / total_weight
    verdict = _verdict_from_score(final_score)

    return EnsembleResult(
        verdict=verdict,
        score=final_score,
        confidence=_calculate_confidence(results),
        reasoning=_generate_explanation(results)
    )
```

### 4. Calibration Module (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

```python
class CalibrationModule:
    """å°‘é‡ã®äººé–“ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§LLM Judgeã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ãƒˆ"""

    def __init__(self, ground_truth_data: List[GroundTruthSample]):
        self.gt_data = ground_truth_data
        self.regression_model = None

    def train(self, llm_predictions: List[LLMJudgeResult]):
        """å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
        # LLMã‚¹ã‚³ã‚¢ã¨äººé–“è©•ä¾¡ã®å·®åˆ†ã‚’å­¦ç¿’
        X = np.array([[p.score, p.confidence] for p in llm_predictions])
        y = np.array([gt.human_score for gt in self.gt_data])

        self.regression_model = LinearRegression()
        self.regression_model.fit(X, y)

    def calibrate(self, raw_score: float, confidence: float) -> float:
        """ç”Ÿã‚¹ã‚³ã‚¢ã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ãƒˆ"""
        if not self.regression_model:
            return raw_score

        calibrated = self.regression_model.predict([[raw_score, confidence]])[0]
        return np.clip(calibrated, 0.0, 1.0)
```

---

## ğŸ“Š å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰
- [ ] `MultiModelJudgeConfig` ã®å®Ÿè£…
- [ ] è¤‡æ•°ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£…ï¼ˆOpenAI, Anthropic, Googleï¼‰
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆAPIåˆ¶é™ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
- [ ] ã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ï¼‰

### Phase 2: Position Biaså¯¾ç­–ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰
- [ ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé †åºãƒ©ãƒ³ãƒ€ãƒ åŒ–ã®å®Ÿè£…
- [ ] è¤‡æ•°å›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨å¹³å‡åŒ–
- [ ] è©•ä¾¡çµæœã®åˆ†æ•£è¨ˆç®—ï¼ˆä¿¡é ¼åº¦æŒ‡æ¨™ï¼‰

### Phase 3: Ensemble Aggregationï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰
- [ ] Majority Votingå®Ÿè£…
- [ ] Minority-Vetoæˆ¦ç•¥å®Ÿè£…
- [ ] Weighted Votingå®Ÿè£…
- [ ] ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®ç®—å‡º

### Phase 4: Calibrationæ©Ÿèƒ½ï¼ˆå„ªå…ˆåº¦: ä¸­ï¼‰
- [ ] Ground Truthãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®šç¾©
- [ ] å›å¸°ãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…
- [ ] ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ç¶™ç¶šçš„æ›´æ–°

### Phase 5: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨æ”¹å–„ï¼ˆå„ªå…ˆåº¦: ä½ï¼‰
- [ ] Judgeé–“ã®ä¸€è‡´ç‡ï¼ˆInter-Judge Agreementï¼‰ã®å¯è¦–åŒ–
- [ ] Position Biasã®æ¤œå‡ºã¨å ±å‘Š
- [ ] ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®A/Bãƒ†ã‚¹ãƒˆ

---

## ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æ

### ç¾çŠ¶ï¼ˆå˜ä¸€ãƒ¢ãƒ‡ãƒ«ï¼‰
- ãƒ¢ãƒ‡ãƒ«: GPT-4o
- 1è³ªå•ã‚ãŸã‚Šè©•ä¾¡: 1å›
- æƒ³å®šãƒˆãƒ¼ã‚¯ãƒ³: å…¥åŠ›500 + å‡ºåŠ›100 = 600ãƒˆãƒ¼ã‚¯ãƒ³
- ã‚³ã‚¹ãƒˆ: $0.003 / 1Kå…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ + $0.015 / 1Kå‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ = **ç´„$0.0027 per question**

### ææ¡ˆï¼ˆ3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« + Position Randomizationï¼‰
- ãƒ¢ãƒ‡ãƒ«: GPT-4o, Claude 3.5 Sonnet, Gemini 2.0 Flash
- 1è³ªå•ã‚ãŸã‚Šè©•ä¾¡: 3ãƒ¢ãƒ‡ãƒ« Ã— 2å›ï¼ˆä½ç½®ãƒ©ãƒ³ãƒ€ãƒ åŒ–ï¼‰= 6å›
- æƒ³å®šãƒˆãƒ¼ã‚¯ãƒ³: 600ãƒˆãƒ¼ã‚¯ãƒ³ Ã— 6 = 3,600ãƒˆãƒ¼ã‚¯ãƒ³
- ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š:
  - GPT-4o: $0.0027 Ã— 2 = $0.0054
  - Claude 3.5 Sonnet: $0.003 Ã— 2 = $0.006 (å…¥åŠ›$3/MTok, å‡ºåŠ›$15/MTok)
  - Gemini 2.0 Flash: $0.0001 Ã— 2 = $0.0002 (å…¥åŠ›$0.10/MTok, å‡ºåŠ›$0.40/MTok)
- **åˆè¨ˆ: ç´„$0.0116 per question (ç´„4.3å€)**

### ã‚³ã‚¹ãƒˆæœ€é©åŒ–æ¡ˆ
1. **æ®µéšçš„è©•ä¾¡**: æœ€åˆã¯Gemini Flashã§è©•ä¾¡ã—ã€ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„å ´åˆã®ã¿é«˜ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ 
2. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨**: åŒä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨
3. **ãƒãƒƒãƒå‡¦ç†**: è¤‡æ•°è³ªå•ã‚’ã¾ã¨ã‚ã¦è©•ä¾¡

---

## ğŸ§ª è©•ä¾¡æŒ‡æ¨™

### 1. Judgeé–“ä¸€è‡´ç‡ï¼ˆInter-Judge Agreementï¼‰
```python
def calculate_fleiss_kappa(judge_verdicts: List[List[str]]) -> float:
    """Fleiss' Kappaã§è¤‡æ•°Judgeé–“ã®ä¸€è‡´åº¦ã‚’æ¸¬å®š"""
    # å®Ÿè£…: statsmodels.stats.inter_rater.fleiss_kappa
    pass
```

### 2. Position Biasæ¤œå‡º
```python
def detect_position_bias(results_by_position: Dict[int, List[float]]) -> float:
    """ä½ç½®ã«ã‚ˆã‚‹è©•ä¾¡ã®åã‚Šã‚’æ¤œå‡º"""
    position_scores = [np.mean(scores) for scores in results_by_position.values()]
    return np.std(position_scores)  # æ¨™æº–åå·®ãŒå¤§ãã„ = ãƒã‚¤ã‚¢ã‚¹å¤§
```

### 3. Calibration Error
```python
def calculate_calibration_error(
    predicted_scores: List[float],
    ground_truth_scores: List[float]
) -> float:
    """äºˆæ¸¬ã‚¹ã‚³ã‚¢ã¨å®Ÿéš›ã®ã‚¹ã‚³ã‚¢ã®èª¤å·®"""
    return mean_absolute_error(ground_truth_scores, predicted_scores)
```

---

## ğŸ¯ æ¨å¥¨äº‹é …

### å³åº§ã«å®Ÿè£…ã™ã¹ãï¼ˆPhase 1-2ï¼‰
1. **3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**: GPT-4o, Claude 3.5, Gemini 2.0 Flash
2. **Minority-Vetoæˆ¦ç•¥**: 1ã¤ã§ã‚‚é‡å¤§ãªå•é¡Œã‚’æ¤œå‡ºã—ãŸã‚‰ reject
3. **Position Randomization**: å„ãƒ¢ãƒ‡ãƒ«ã§2å›è©•ä¾¡ã—å¹³å‡åŒ–

### ä¸­æœŸçš„ã«å®Ÿè£…ï¼ˆPhase 3-4ï¼‰
4. **Weighted Voting**: ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼åº¦ã«åŸºã¥ãåŠ é‡æŠ•ç¥¨
5. **Calibration**: äººé–“è©•ä¾¡100ä»¶ã‚’åé›†ã—ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

### é•·æœŸçš„æ”¹å–„ï¼ˆPhase 5ï¼‰
6. **ç¶™ç¶šçš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**: Judgeé–“ä¸€è‡´ç‡ã€Position Biasã®å®šæœŸæ¸¬å®š
7. **A/Bãƒ†ã‚¹ãƒˆ**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®æ¯”è¼ƒè©•ä¾¡
8. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: æ®µéšçš„è©•ä¾¡ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨

---

## ğŸ¤– LLM as a Judge ã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã®ç‰¹æ®Šæ€§

### Agent-as-a-Judge ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

å¾“æ¥ã®ã€ŒLLM as a Judgeã€ã¯ä¸»ã«**å˜ä¸€ã‚¿ãƒ¼ãƒ³ã®å¿œç­”å“è³ª**ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã ãŒã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ–ã§ã¯**ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã®è©•ä¾¡ãŒå¿…è¦ã€‚ã“ã®å ´åˆã€**Agent-as-a-Judge**ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒæœ‰åŠ¹ï¼š

#### è©•ä¾¡ã™ã¹ã4ã¤ã®å´é¢

1. **ã‚¿ã‚¹ã‚¯å®Œé‚æ€§ (Task Completion)**
   - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®ç›®çš„ã‚’é”æˆã—ãŸã‹
   - å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦å®Ÿè¡Œã—ãŸã‹
   - ä¾‹: ã€Œå¤©æ°—äºˆå ±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãŒä½ç½®æƒ…å ±ã‚’å–å¾—ã—ã€APIã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ãŸã‹

2. **ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®æ­£ç¢ºæ€§ (Tool Correctness)**
   - é©åˆ‡ãªãƒ„ãƒ¼ãƒ«/APIã‚’é¸æŠã—ãŸã‹
   - å¼•æ•°ãŒæ­£ã—ãæ¸¡ã•ã‚ŒãŸã‹
   - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒã§ãã¦ã„ã‚‹ã‹

3. **å¯¾è©±å“è³ª (Conversation Quality)**
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æ­£ã—ãç†è§£ã—ãŸã‹
   - å¿œç­”ãŒè‡ªç„¶ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‹
   - å¿…è¦ãªæƒ…å ±ã‚’é©åˆ‡ã«è³ªå•ã—ãŸã‹

4. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒ (Memory Retention)**
   - ä¼šè©±å±¥æ­´ã‚’æ­£ã—ãå‚ç…§ã—ã¦ã„ã‚‹ã‹
   - è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã«ã‚ãŸã‚‹æƒ…å ±ã‚’è¨˜æ†¶ã—ã¦ã„ã‚‹ã‹
   - ãƒˆãƒ”ãƒƒã‚¯è»¢æ›æ™‚ã«é©åˆ‡ã«å¯¾å¿œã—ã¦ã„ã‚‹ã‹

### ç¾åœ¨ã® Judge Panel ã®è©•ä¾¡ç¯„å›²

```python
# prototype/inspect-worker/inspect_worker/judge_orchestrator.py
stages = ["plan", "counter", "reconcile"]
```

ç¾åœ¨ã®å®Ÿè£…ã§ã¯ä¸»ã«**å˜ä¸€ã‚¿ãƒ¼ãƒ³ã®å¿œç­”å“è³ª**ï¼ˆå¯¾è©±å“è³ªã®ä¸€éƒ¨ï¼‰ã®ã¿è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç‰¹æœ‰ã®è©•ä¾¡ï¼ˆã‚¿ã‚¹ã‚¯å®Œé‚ã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒï¼‰ãŒä¸è¶³ã€‚

### æ¨å¥¨æ”¹å–„: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

```python
def _build_agent_evaluation_prompt(
    self,
    use_case: str,
    conversation_history: List[Message],
    tool_usage: List[ToolCall],
    final_response: str
) -> str:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå°‚ç”¨ã®è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    return f"""
You are evaluating an AI agent's performance on the following use case:
Use Case: {use_case}

Conversation History:
{format_conversation(conversation_history)}

Tool Usage Log:
{format_tool_calls(tool_usage)}

Final Response:
{final_response}

Evaluate the agent on these criteria (0-100 each):

1. Task Completion (0-40 points):
   - Did the agent accomplish the stated use case goal?
   - Were all necessary steps executed?
   - Score: [0-40]

2. Tool Correctness (0-30 points):
   - Were appropriate tools selected?
   - Were tool arguments correct?
   - Was error handling adequate?
   - Score: [0-30]

3. Conversation Quality (0-20 points):
   - Did the agent understand user intent?
   - Were responses clear and natural?
   - Did the agent ask appropriate clarifying questions?
   - Score: [0-20]

4. Context Retention (0-10 points):
   - Did the agent remember previous conversation context?
   - Did it handle topic transitions appropriately?
   - Score: [0-10]

Provide your evaluation in JSON format:
{{
  "task_completion": <score>,
  "tool_correctness": <score>,
  "conversation_quality": <score>,
  "context_retention": <score>,
  "total_score": <sum>,
  "verdict": "approve" | "reject" | "manual",
  "reasoning": "<detailed explanation>"
}}
"""
```

### å®Ÿè£…å„ªå…ˆåº¦

#### Phase 1ï¼ˆæ—¢å­˜Judge Panelã®æ”¹å–„ - ã¾ãšå®Ÿè£…ã™ã¹ãï¼‰:
1. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®ç½®ãæ›ãˆ**
   - ç¾åœ¨ã®`plan/counter/reconcile`ã‚’å»ƒæ­¢
   - ä¸Šè¨˜ã®4å´é¢è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›´
   - å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã‚‚è©•ä¾¡ç²¾åº¦ãŒå‘ä¸Š

#### Phase 2ï¼ˆMulti-Model Ensemble - æ¬¡ã«å®Ÿè£…ï¼‰:
2. **3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**ï¼ˆæœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®Phase 1-3ï¼‰
3. **Position Randomization**
4. **Minority-Vetoæˆ¦ç•¥**

#### Phase 3ï¼ˆé«˜åº¦ãªæ©Ÿèƒ½ - å°†æ¥çš„ã«å®Ÿè£…ï¼‰:
5. **Calibration**ï¼ˆäººé–“è©•ä¾¡100ä»¶ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
6. **ç¶™ç¶šçš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**

---

## ğŸ“ å‚è€ƒæ–‡çŒ®

1. Zheng et al. (2023). "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena"
2. arXiv 2024. "Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations"
3. arXiv 2024. "Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems"
4. Cameron R. Wolfe. "Using LLMs for Evaluation" (Substack blog)
5. **Agent-as-a-Judge Framework**: Survey on evaluating LLM-based agents for multi-turn conversations (2024)
6. **Multi-Turn Agent Evaluation**: Task completion, tool correctness, conversation quality, memory retention

---

## ğŸ”— é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—](./trust-score-implementation-roadmap.md)
- [Judge Panelå®Ÿè£…ã‚¬ã‚¤ãƒ‰](./judge-panel-human-review-implementation-20251110.md)
- [Review Pipeline Workflow](../../prototype/temporal-review-workflow/src/workflows/reviewPipeline.workflow.ts)
- [LLM Judgeå®Ÿè£…](../../prototype/inspect-worker/inspect_worker/llm_judge.py)
